{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "artistic-catch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything is the same with Task A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import emoji\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from transformers import get_constant_schedule_with_warmup, get_linear_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from transformers import DistilBertTokenizerFast, BertTokenizerFast\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments, BertForSequenceClassification\n",
    "from pathlib import Path\n",
    "from scipy.special import softmax\n",
    "\n",
    "# specify GPU device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def remove_emoji(s):\n",
    "    return emoji.get_emoji_regexp().sub(u'', s)\n",
    "    \n",
    "def count_trainable_paras(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params\n",
    "\n",
    "def count_word(s, w):\n",
    "    return s.count(w)\n",
    "  \n",
    "def preprocessing_sent(s):\n",
    "    # Lower\n",
    "    #s = segment(s)\n",
    "    #s = ' '.join(s)\n",
    "    s = s.lower()\n",
    "    s = s.replace('url', 'http')\n",
    "    #s = s.replace('#', '')\n",
    "    #s = s.replace('@', '')\n",
    "    #s = remove_emoji(s)\n",
    "    s = emoji.demojize(s)\n",
    "    return s\n",
    "\n",
    "# Change the Data Directory here\n",
    "DATA_DIR = '/home/nmduy/NUIG/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-button",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aggressive-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess tweet\n",
    "data = pd.read_csv(f'{DATA_DIR}/olid-training-v1.0.tsv', sep='\\t')\n",
    "data = data.drop(columns=['subtask_a', 'subtask_c'])\n",
    "data = data.dropna(subset=['subtask_b'])\n",
    "data.columns = ['id', 'tweet', 'label']\n",
    "label = {'TIN': 1,'UNT': 0}\n",
    "data.label = [label[item] for item in data.label]\n",
    "data['tweet_demojize'] = [preprocessing_sent(x) for x in data.tweet.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "occupational-premiere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#whoisq #wherestheserver #dumpnike #declasfisa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#nopasaran: unity demo to oppose the far-right...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>. . . what the fuck did he do this time?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@user do you get the feeling he is kissing @us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user nigga ware da hits at</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  #whoisq #wherestheserver #dumpnike #declasfisa...      1\n",
       "1  #nopasaran: unity demo to oppose the far-right...      1\n",
       "2           . . . what the fuck did he do this time?      1\n",
       "3  @user do you get the feeling he is kissing @us...      1\n",
       "4                        @user nigga ware da hits at      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.tweet_demojize.to_frame()\n",
    "y = data.label.to_frame()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,stratify=y, test_size=0.2, random_state=1509)\n",
    "\n",
    "data_train = X_train.copy()\n",
    "data_train['label'] = y_train.label.tolist()\n",
    "\n",
    "data_val = X_val.copy()\n",
    "data_val['label'] = y_val.label.tolist()\n",
    "\n",
    "data_train.columns = ['tweet', 'label']\n",
    "data_val.columns = ['tweet', 'label']\n",
    "\n",
    "# Create TEST SET\n",
    "data_test = pd.read_csv(f'{DATA_DIR}/testset-levelb.tsv', sep='\\t')\n",
    "data_test['tweet_demojize'] = [preprocessing_sent(x) for x in data_test.tweet.tolist()]\n",
    "data_test.columns = ['id', 'tweet', 'tweet_demojize']\n",
    "\n",
    "# Read label test set\n",
    "label_test = pd.read_csv(f'{DATA_DIR}/labels-levelb.csv', header=None)\n",
    "label_test.columns = ['id', 'label']\n",
    "label = {'TIN': 1,'UNT': 0}\n",
    "data_test_id = data_test['id'].tolist()\n",
    "data_test_label = label_test['label'].tolist()\n",
    "label_test.label = [label[item] for item in label_test.label]\n",
    "\n",
    "data_test = pd.merge(data_test, label_test, on='id')\n",
    "data_test = data_test.drop(columns=['id', 'tweet'])\n",
    "data_test.columns = ['tweet', 'label']\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-collection",
   "metadata": {},
   "source": [
    "# Apply BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accomplished-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "    preds_logits = torch.tensor(pred.predictions)\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    loss = loss_fct(preds_logits.view(-1,2), labels_tensor.view(-1)) # 2 class\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'lof1': 1 - loss + f1 # take both loss and F1 score into account\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fitted-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.tweet.tolist()\n",
    "X_val = data_val.tweet.tolist()\n",
    "X_test = data_test.tweet.tolist()\n",
    "\n",
    "Y_train = data_train.label.tolist()\n",
    "Y_val = data_val.label.tolist()\n",
    "Y_test = data_test.label.tolist()\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "#tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "X_encoding_train = tokenizer(list(map(str, X_train)), truncation=True, padding=True)\n",
    "X_encoding_val = tokenizer(list(map(str, X_val)), truncation=True, padding=True)\n",
    "X_encoding_test = tokenizer(list(map(str, X_test)), truncation=True, padding=True)\n",
    "\n",
    "train_ds = TweetDataset(X_encoding_train, Y_train)\n",
    "val_ds = TweetDataset(X_encoding_val, Y_val)\n",
    "test_ds = TweetDataset(X_encoding_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "coordinated-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = Path('results_B')\n",
    "LOG_DIR = Path('logs_B')\n",
    "EPOCHES = 10 # converge after 7-8 epochs\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(OUTPUT_DIR),\n",
    "    num_train_epochs=EPOCHES,              \n",
    "    per_device_train_batch_size=BATCH_SIZE,  \n",
    "    per_device_eval_batch_size=BATCH_SIZE*4,   \n",
    "    warmup_steps=200,               \n",
    "    weight_decay=0.01,          \n",
    "    logging_dir=str(LOG_DIR),\n",
    "    logging_steps=200,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    seed=1509,\n",
    "    learning_rate=8e-6,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_lof1',\n",
    "    greater_is_better=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "indie-blogger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
    "#model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "arabic-passion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1100/1100 03:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Lof1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.382505</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.468278</td>\n",
       "      <td>0.440341</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.085773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.489300</td>\n",
       "      <td>0.349925</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.468278</td>\n",
       "      <td>0.440341</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.118353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.489300</td>\n",
       "      <td>0.345133</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.468278</td>\n",
       "      <td>0.440341</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.123146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.338468</td>\n",
       "      <td>0.879545</td>\n",
       "      <td>0.467956</td>\n",
       "      <td>0.440273</td>\n",
       "      <td>0.499355</td>\n",
       "      <td>1.129488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.335632</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.519328</td>\n",
       "      <td>0.692972</td>\n",
       "      <td>0.524700</td>\n",
       "      <td>1.183696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.299700</td>\n",
       "      <td>0.345958</td>\n",
       "      <td>0.878409</td>\n",
       "      <td>0.552469</td>\n",
       "      <td>0.674260</td>\n",
       "      <td>0.543994</td>\n",
       "      <td>1.206511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.299700</td>\n",
       "      <td>0.361933</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.617567</td>\n",
       "      <td>0.677443</td>\n",
       "      <td>0.595576</td>\n",
       "      <td>1.255634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.372051</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.608611</td>\n",
       "      <td>0.674550</td>\n",
       "      <td>0.587343</td>\n",
       "      <td>1.236559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.391158</td>\n",
       "      <td>0.873864</td>\n",
       "      <td>0.602718</td>\n",
       "      <td>0.668269</td>\n",
       "      <td>0.582581</td>\n",
       "      <td>1.211560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.201600</td>\n",
       "      <td>0.396695</td>\n",
       "      <td>0.873864</td>\n",
       "      <td>0.602718</td>\n",
       "      <td>0.668269</td>\n",
       "      <td>0.582581</td>\n",
       "      <td>1.206024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nmduy/anaconda3/envs/omnigo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nmduy/anaconda3/envs/omnigo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nmduy/anaconda3/envs/omnigo/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1100, training_loss=0.30050459081476383, metrics={'train_runtime': 226.6638, 'train_samples_per_second': 4.853, 'total_flos': 0, 'epoch': 10.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=training_args, \n",
    "                  train_dataset=train_ds, eval_dataset=val_ds, \n",
    "                  compute_metrics = compute_metrics)\n",
    "trainer.train()\n",
    "# 1 or 2 first epoch will have a very bad result but it will improve later\n",
    "# only save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "several-medicaid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.27218863368034363,\n",
       " 'test_accuracy': 0.8916666666666667,\n",
       " 'test_f1': 0.719626168224299,\n",
       " 'test_precision': 0.7274418604651163,\n",
       " 'test_recall': 0.7125717266562337,\n",
       " 'test_lof1': 1.4474376440048218,\n",
       " 'test_runtime': 0.2513,\n",
       " 'test_samples_per_second': 955.144}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = trainer.predict(test_ds)\n",
    "prob_test = softmax(pred_test.predictions, axis=1)[:, 1]\n",
    "pred_test.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['subtask_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-hamilton",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
